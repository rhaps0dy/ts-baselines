{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will write files to ./interpolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6745it [06:58,  9.01it/s]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle_utils as pu\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import collections\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "sys.path.insert(0, os.path.join('.', 'GRUD-baseline'))\n",
    "from read_tfrecords import build_input_machinery\n",
    "\n",
    "dataset='clean_ventilation/dataset/train_0.tfrecords'\n",
    "\n",
    "assert os.path.exists(dataset)\n",
    "\n",
    "if not os.path.exists('interpolation'):\n",
    "    os.mkdir('interpolation')\n",
    "print(\"Will write files to ./interpolation\")\n",
    "\n",
    "feature_numbers = pu.load(os.path.join(\n",
    "    os.path.dirname(dataset), 'feature_numbers.pkl.gz'))\n",
    "dataset = build_input_machinery([dataset], feature_numbers, False, 1,\n",
    "                                BATCH_SIZE, None, 1)\n",
    "\n",
    "num_shape = [BATCH_SIZE, int(dataset['numerical_ts'].get_shape()[2])]\n",
    "last_num_ts = np.empty(num_shape, dtype=np.float32)\n",
    "num_ts_dt = np.zeros(num_shape, dtype=np.int)\n",
    "\n",
    "cat_shape = [BATCH_SIZE, int(dataset['categorical_ts'].get_shape()[2])]\n",
    "last_cat_ts = -np.ones(cat_shape, dtype=np.int32) # all -1\n",
    "cat_ts_dt = np.zeros(cat_shape, dtype=np.int)\n",
    "\n",
    "num_interpolate_X = list([] for _ in range(num_shape[1]))\n",
    "num_interpolate_y = list([] for _ in range(num_shape[1]))\n",
    "cat_interpolate_X = list([] for _ in range(cat_shape[1]))\n",
    "cat_interpolate_y = list([] for _ in range(cat_shape[1]))\n",
    "\n",
    "category_counts = list(collections.Counter() for _ in range(cat_shape[1]))\n",
    "numerical_averages = np.zeros(num_shape[1], dtype=np.float32)\n",
    "numerical_averages_counts = np.zeros(num_shape[1], dtype=np.int)\n",
    "numerical_averages_counts_2 = np.zeros(num_shape[1], dtype=np.int)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "coord = tf.train.Coordinator()\n",
    "queue_threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "progress_bar = tqdm()\n",
    "try:\n",
    "    while not coord.should_stop():\n",
    "        numerical_ts, categorical_ts, length = sess.run(list(map(\n",
    "            dataset.__getitem__, ['numerical_ts', 'categorical_ts', 'length'])))\n",
    "        for feature_i in range(cat_shape[1]):\n",
    "            category_counts[feature_i].update(categorical_ts[:,:,feature_i].flatten())\n",
    "\n",
    "        progress_bar.update(n=numerical_ts.shape[0])\n",
    "        if numerical_ts.shape[0] < num_shape[0]:\n",
    "            # Pad so that the first dimension is always BATCH_SIZE\n",
    "            numerical_ts = np.pad(\n",
    "                numerical_ts,\n",
    "                [(0, num_shape[0]-numerical_ts.shape[0]), (0, 0), (0, 0)],\n",
    "                'constant', constant_values=np.nan)\n",
    "            categorical_ts = np.pad(\n",
    "                categorical_ts,\n",
    "                [(0, cat_shape[0]-categorical_ts.shape[0]), (0, 0), (0, 0)],\n",
    "                'constant', constant_values=-1)\n",
    "            length = np.pad(\n",
    "                length,\n",
    "                [(0, num_shape[0]-length.shape[0])],\n",
    "                'constant', constant_values=0)\n",
    "\n",
    "        last_num_ts[:] = np.nan\n",
    "        num_ts_dt[:] = 0\n",
    "        last_cat_ts[:] = -1\n",
    "        cat_ts_dt[:] = 0\n",
    "        for t in range(numerical_ts.shape[1]):\n",
    "            num_ts = numerical_ts[:,t,:]\n",
    "            cat_ts = categorical_ts[:,t,:]\n",
    "            assert num_ts.shape[1] == num_shape[1]\n",
    "            assert cat_ts.shape[1] == cat_shape[1]\n",
    "\n",
    "            is_in_range = (t < length)[:,None]\n",
    "            num_is_valid = is_in_range * (~np.isnan(num_ts))\n",
    "\n",
    "            for ex, f in zip(*num_is_valid.nonzero()):\n",
    "                n = last_num_ts[ex,f]\n",
    "                if not np.isnan(n):\n",
    "                    num_interpolate_X[f].append((n, num_ts_dt[ex,f]))\n",
    "                    num_interpolate_y[f].append((num_ts[ex,f]))\n",
    "                numerical_averages[f] += num_ts[ex,f]\n",
    "                numerical_averages_counts_2[f] += 1\n",
    "            numerical_averages_counts += np.sum(num_is_valid, axis=0)\n",
    "\n",
    "            cat_is_valid = is_in_range * (cat_ts >= 0)\n",
    "            for ex, f in zip(*cat_is_valid.nonzero()):\n",
    "                n = last_cat_ts[ex,f]\n",
    "                if n >= 0:\n",
    "                    cat_interpolate_X[f].append((n, cat_ts_dt[ex,f]))\n",
    "                    cat_interpolate_y[f].append((cat_ts[ex,f]))\n",
    "\n",
    "            num_ts_dt += 1\n",
    "            num_ts_dt[num_is_valid] = 0\n",
    "            last_num_ts[num_is_valid] = num_ts[num_is_valid]\n",
    "            cat_ts_dt += 1\n",
    "            cat_ts_dt[cat_is_valid] = 0\n",
    "            last_cat_ts[cat_is_valid] = cat_ts[cat_is_valid]\n",
    "except tf.errors.OutOfRangeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({-1: 352874,\n",
       "         0: 8402446,\n",
       "         1: 26269,\n",
       "         2: 2079,\n",
       "         3: 3120,\n",
       "         4: 944,\n",
       "         5: 19719,\n",
       "         6: 314,\n",
       "         7: 3,\n",
       "         8: 4,\n",
       "         9: 4,\n",
       "         10: 1,\n",
       "         11: 12,\n",
       "         12: 1,\n",
       "         13: 13669})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts[108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#for i, niX, niY in zip(it.count(0), num_interpolate_X, num_interpolate_y):\n",
    "#    pu.dump((niX, niY), 'interpolation/num_{:d}.pkl.gz'.format(i))\n",
    "#for i, ciX, ciY in zip(it.count(0), cat_interpolate_X, cat_interpolate_y):\n",
    "#    pu.dump((ciX, ciY), 'interpolation/cat_{:d}.pkl.gz'.format(i))\n",
    "nums_cats = pu.load('dataset/number_of_categories_200.pkl.gz')['categorical_ts']\n",
    "for i, (count, n_cats) in enumerate(zip(category_counts, nums_cats)):\n",
    "    a = np.zeros(n_cats, dtype=np.int)\n",
    "    try:\n",
    "        for cat, n in count.items():\n",
    "            a[cat] = n\n",
    "    except IndexError:\n",
    "        print(\"Index error on\", i, count)\n",
    "    pu.dump(a, 'interpolation/counts_cat_{:d}.pkl.gz'.format(i))\n",
    "pu.dump((numerical_averages, numerical_averages_counts_2), 'dataset/means.pkl.gz')\n",
    "assert np.all(numerical_averages_counts_2 == numerical_averages_counts)\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(queue_threads)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

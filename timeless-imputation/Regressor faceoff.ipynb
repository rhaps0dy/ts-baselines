{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle_utils as pu\n",
    "import imp\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dset = datasets.datasets()[\"BostonHousing\"][0].astype(np.float64)\n",
    "dset = pu.load(\"impute_benchmark/amputed_BostonHousing_MCAR_rows_0.3.pkl.gz\")\n",
    "mog = pu.load(\"impute_benchmark/imputed_BGMM_20_BostonHousing_MCAR_rows_0.3/params.pkl.gz\")\n",
    "mog['means'] = mog['means'][:, 1:]\n",
    "mog['covariances'] = mog['covariances'][:, 1:, 1:]\n",
    "\n",
    "test_mask = np.random.rand(len(dset)) < 0.2\n",
    "\n",
    "norm_mean = dset[~test_mask].mean()\n",
    "norm_std = dset[~test_mask].std()\n",
    "\n",
    "dset = (dset - norm_mean) / norm_std\n",
    "dset_nan = dset.copy()\n",
    "dset = dset.fillna(0)\n",
    "dset_var = dset.applymap(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "y_train = dset.values[~test_mask, 0]\n",
    "X_train = dset.values[~test_mask, 1:]\n",
    "X_train_var = dset_var.values[~test_mask, 1:]\n",
    "X_train_nan = dset_nan.values[~test_mask, 1:]\n",
    "y_test = dset.values[test_mask, 0]\n",
    "X_test = dset.values[test_mask, 1:]\n",
    "X_test_var = dset_var.values[test_mask, 1:]\n",
    "X_test_nan = dset_nan.values[test_mask, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r_squared(y_true, y):\n",
    "    u = np.sum((y-y_true)**2)\n",
    "    v = np.sum((y_true - np.mean(y_true))**2)\n",
    "    return 1 - u/v\n",
    "def rmse(y_true, y):\n",
    "    return np.mean((y_true - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False, True, True, False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(y_train)), np.all(np.isfinite(X_train)), np.all(np.isfinite(X_train_nan)), np.all(np.isfinite(y_test)), np.all(np.isfinite(X_test)), np.all(np.isfinite(X_test_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 0.2677, Training: 0.9549\n",
      "Train: 0.0315987105856\n",
      "Test: 2.34436448443\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1,\n",
    "                           max_features=int(np.floor(X_train.shape[1])/3),\n",
    "                           bootstrap=False,\n",
    "                           min_samples_split=5)\n",
    "rf.fit(X_train, y_train)\n",
    "train_perf = rf.score(X_train, y_train)\n",
    "test_perf = rf.score(X_test, y_test)\n",
    "print(\"Test: {:.4f}, Training: {:.4f}\".format(test_perf, train_perf))\n",
    "y = rf.predict(X_train)\n",
    "print(\"Train:\", rmse(y_train, y.flatten()))\n",
    "y = rf.predict(X_test)\n",
    "print(\"Test:\", rmse(y_test, y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.262916908349\n",
      "Test: 1.22404203677\n"
     ]
    }
   ],
   "source": [
    "import GPy\n",
    "m = GPy.models.GPRegression(X_train, y_train[:,np.newaxis],\n",
    "                            kernel=GPy.kern.Matern32(X_train.shape[1], ARD=True) + GPy.kern.White(X_train.shape[1]))\n",
    "#m.optimize()\n",
    "y, _ = m.predict(X_train)\n",
    "print(\"Train:\", rmse(y_train, y.flatten()))\n",
    "y, _ = m.predict(X_test)\n",
    "print(\"Test:\", rmse(y_test, y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  sum.           </b></th><th><b>         value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  rbf.variance   </td><td class=tg-right> 0.55463044994</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale</td><td class=tg-right> 2.04190842862</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  white.variance </td><td class=tg-right>0.165010421819</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.kern.src.add.Add at 0x7f9b7421b278>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.kern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-0.42006788,  1.01905536,  0.68299323, -0.40612554,  0.63205938,\n",
       "          -0.5832783 ,  0.39105928,  0.67011543,  0.35313276, -0.21148562,\n",
       "           0.3739001 ,  1.10710231]]]),\n",
       " array([[ 0.63855337,  0.32716695,  0.        ,  1.04207718, -0.0528659 ,\n",
       "          1.04048448,  0.61910684,  0.2997959 ,  0.54710433,  1.24750701,\n",
       "          0.30055021,  0.        ]]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(gmm_impute)\n",
    "gmm_impute._gmm_impute(mog, X_train_nan[9:10], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        nan,         nan,  0.68299323,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,  1.10710231]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_nan[9:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-0.42006788],\n",
       "         [ 1.01905536],\n",
       "         [-0.40612554],\n",
       "         [ 0.63205938],\n",
       "         [-0.5832783 ],\n",
       "         [ 0.39105928],\n",
       "         [ 0.67011543],\n",
       "         [ 0.35313276],\n",
       "         [-0.21148562],\n",
       "         [ 0.3739001 ]]]),\n",
       " array([[[ 0.63855337,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.32716695,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  1.04207718,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -0.0528659 ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  1.04048448,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.61910684,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.2997959 ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.54710433,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  1.24750701,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.30055021]]]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(mog_rbf)\n",
    "d = mog_rbf.uncertain_point(X_train_nan[9], mog, 1., np.eye(12), single_gaussian_moment_matching=True)\n",
    "d['means'], d['covariances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To compute map took me: 0.4738774299621582\n",
      "FOR REAL [[[-0.15875905]\n",
      "  [ 0.17830032]\n",
      "  [-0.41094708]\n",
      "  [-0.40360746]]]\n"
     ]
    }
   ],
   "source": [
    "imp.reload(mog_rbf)\n",
    "imp.reload(gmm_impute)\n",
    "uk2 = mog_rbf.UncertainMoGRBFWhite(X_train.shape[1], mog, cutoff=1.0, single_gaussian=True)\n",
    "K_uk2 = uk2.K(X_train_nan, X_train_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: you passed a MoG to a GaussianRBFWhite kernel\n",
      "To compute map (rectangular) took me: 0.9276993274688721\n",
      "To compute matrix took me: 0.2105269432067871\n",
      "(408, 408)\n"
     ]
    }
   ],
   "source": [
    "imp.reload(mog_rbf)\n",
    "imp.reload(gmm_impute)\n",
    "uk3 = mog_rbf.UncertainGaussianRBFWhite(X_train.shape[1], mog)\n",
    "K_uk3 = uk3.K(X_train_nan, X_train_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00090383853741499674"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(K_uk3 - K_uk3.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To compute map took me: 0.38788938522338867\n",
      "To compute matrix took me: 5.707479238510132\n",
      "To compute map took me: 0.38481831550598145\n",
      "To compute matrix took me: 11.051551580429077\n",
      "Train: 0.303080763536\n",
      "To compute map took me: 0.4139392375946045\n",
      "To compute matrix took me: 2.8104450702667236\n",
      "Test: 2.51814645194\n"
     ]
    }
   ],
   "source": [
    "import mog_rbf\n",
    "import imp\n",
    "import gmm_impute\n",
    "imp.reload(gmm_impute)\n",
    "imp.reload(mog_rbf)\n",
    "\n",
    "uncertain_kern = mog_rbf.UncertainMoGRBFWhite(X_train.shape[1], mog)\n",
    "uncertain_k = GPy.models.GPRegression(X_train_nan, y_train[:, np.newaxis],\n",
    "                                     kernel=uncertain_kern)\n",
    "y, _ = uncertain_k.predict(X_train_nan)\n",
    "print(\"Train:\", rmse(y_train, y.flatten()))\n",
    "y, _ = uncertain_k.predict(X_test_nan)\n",
    "print(\"Test:\", rmse(y_test, y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: you passed a MoG to a GaussianRBFWhite kernel\n",
      "To compute map took me: 0.47240662574768066\n",
      "To compute matrix took me: 0.21442580223083496\n",
      "(408, 408)\n",
      "To compute map (rectangular) took me: 0.9931590557098389\n",
      "To compute matrix took me: 0.2064647674560547\n",
      "(408, 408)\n",
      "Train: 0.323577201919\n",
      "To compute map (rectangular) took me: 0.6183946132659912\n",
      "To compute matrix took me: 0.0666952133178711\n",
      "(408, 98)\n",
      "Test: 2.51151833254\n"
     ]
    }
   ],
   "source": [
    "import mog_rbf\n",
    "import imp\n",
    "import gmm_impute\n",
    "imp.reload(gmm_impute)\n",
    "imp.reload(mog_rbf)\n",
    "\n",
    "uncertain_kern = mog_rbf.UncertainGaussianRBFWhite(X_train.shape[1], mog)\n",
    "uncertain_k = GPy.models.GPRegression(X_train_nan, y_train[:, np.newaxis],\n",
    "                                     kernel=uncertain_kern)\n",
    "y, _ = uncertain_k.predict(X_train_nan)\n",
    "print(\"Train:\", rmse(y_train, y.flatten()))\n",
    "y, _ = uncertain_k.predict(X_test_nan)\n",
    "print(\"Test:\", rmse(y_test, y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/adria/venv/lib/python3.5/site-packages/paramz/transformations.py:109: RuntimeWarning:divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.361617084375\n",
      "Test: 0.0740350690732\n"
     ]
    }
   ],
   "source": [
    "X_train_alt = X_train_nan.copy()\n",
    "X_test_alt = X_test_nan.copy()\n",
    "\n",
    "for i, X in enumerate(X_train_alt):\n",
    "    mask = np.isnan(X)\n",
    "    d = gmm_impute.conditional_mog(mog, X, mask)\n",
    "    # Perform moment matching to get mean and variance\n",
    "    # https://stats.stackexchange.com/questions/16608/what-is-the-variance-of-the-weighted-mixture-of-two-gaussians\n",
    "    ms = d['means'] * d['weights'][:, np.newaxis]\n",
    "    mean = np.sum(ms, axis=0)\n",
    "    var_mix = np.sum(d['covariances'] * np.eye(d['covariances'].shape[1]), axis=2).sum(axis=0)\n",
    "    var = var_mix + np.sum(ms * d['means'], axis=0) - mean\n",
    "    X_train_alt[i, mask] = mean\n",
    "    X_train_var[i, mask] = var\n",
    "\n",
    "for i, X in enumerate(X_test_alt):\n",
    "    mask = np.isnan(X)\n",
    "    d = gmm_impute.conditional_mog(mog, X, mask)\n",
    "    X_test_alt[i, mask] = np.sum(d['means'] * d['weights'][:, np.newaxis], axis=0)\n",
    "\n",
    "\n",
    "sparse_m = GPy.models.SparseGPRegression(\n",
    "    X_train_alt, y_train[:, np.newaxis],\n",
    "    kernel=(GPy.kern.RBF(X_train.shape[1], ARD=False)\n",
    "                   + GPy.kern.White(X_train.shape[1])),\n",
    "    Z=X_train_alt,\n",
    "    X_variance=X_train_var)\n",
    "#sparse_m.optimize()\n",
    "y, _ = sparse_m.predict(X_train_alt)\n",
    "print(\"Train:\", rmse(y_train, y.flatten()))\n",
    "y, full_cov = sparse_m.predict(X_test, full_cov=True)\n",
    "print(\"Test:\", rmse(y_test, y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.78635832e+00,   2.06344958e-04,   1.64838064e-05, ...,\n",
       "          4.35285552e-04,   1.00000000e-15,   8.26572097e-04],\n",
       "       [  2.06344958e-04,   2.94234875e+00,   1.27033141e-03, ...,\n",
       "          4.72627943e-01,   1.00000000e-15,   1.87282191e-02],\n",
       "       [  1.64838064e-05,   1.27033141e-03,   2.78212823e+00, ...,\n",
       "          8.27680241e-04,   2.87765037e-03,   1.40391869e-02],\n",
       "       ..., \n",
       "       [  4.35285552e-04,   4.72627943e-01,   8.27680241e-04, ...,\n",
       "          2.93926028e+00,   1.00000000e-15,   5.84986024e-02],\n",
       "       [  1.00000000e-15,   1.00000000e-15,   2.87765037e-03, ...,\n",
       "          1.00000000e-15,   2.71902756e+00,   1.00000000e-15],\n",
       "       [  8.26572097e-04,   1.87282191e-02,   1.40391869e-02, ...,\n",
       "          5.84986024e-02,   1.00000000e-15,   2.80199682e+00]])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import selu\n",
    "import denoising_ae as dae\n",
    "import imp\n",
    "imp.reload(dae)\n",
    "imp.reload(selu)\n",
    "\n",
    "tf_float = tf.float32\n",
    "tf.reset_default_graph()\n",
    "\n",
    "nn_X = tf.placeholder(tf_float, shape=[None, X_train.shape[1]], name=\"X\")\n",
    "nn_y = tf.placeholder(tf_float, shape=[None, 1], name=\"y\")\n",
    "nn_kp = tf.placeholder(tf_float, shape=[], name=\"keep_prob\")\n",
    "nn_lr = tf.placeholder(tf_float, shape=[], name=\"learning_rate\")\n",
    "\n",
    "\n",
    "nn_preds = dae.FC_net(nn_X, [(1024, selu.nlin)]*8 + [(1, None)], selu.initializer, keep_prob=nn_kp)\n",
    "nn_loss = tf.reduce_mean(tf.squared_difference(nn_preds, nn_y))\n",
    "nn_train = tf.train.GradientDescentOptimizer(nn_lr).minimize(nn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 1it [00:00,  3.25it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 3it [00:00,  4.23it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 5it [00:00,  5.52it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 8it [00:00,  7.19it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 11it [00:00,  9.28it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 14it [00:00, 11.47it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 17it [00:01, 13.87it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 20it [00:01, 16.15it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 23it [00:01, 18.33it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 26it [00:01, 20.51it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 29it [00:01, 21.84it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 32it [00:01, 23.56it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 35it [00:01, 24.51it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 38it [00:01, 25.17it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 41it [00:01, 25.87it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 44it [00:02, 26.36it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 47it [00:02, 26.60it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 50it [00:02, 26.59it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 53it [00:02, 26.87it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 56it [00:02, 27.14it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 59it [00:02, 27.49it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 62it [00:02, 27.45it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 65it [00:02, 27.38it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 68it [00:02, 27.17it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 71it [00:03, 26.09it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 74it [00:03, 26.05it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 77it [00:03, 26.21it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 80it [00:03, 26.16it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 83it [00:03, 26.11it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 86it [00:03, 25.68it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 89it [00:03, 24.57it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 92it [00:03, 24.73it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 95it [00:03, 25.24it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 98it [00:04, 25.93it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 101it [00:04, 17.16it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 104it [00:04, 18.84it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 107it [00:04, 20.02it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 110it [00:04, 21.44it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 113it [00:04, 22.81it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 116it [00:04, 23.97it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 119it [00:05, 24.93it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 122it [00:05, 25.40it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 125it [00:05, 25.89it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 128it [00:05, 26.16it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 131it [00:05, 26.56it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 134it [00:05, 26.75it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 137it [00:05, 26.85it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 140it [00:05, 26.67it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 143it [00:05, 26.69it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 146it [00:06, 26.40it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 149it [00:06, 27.00it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 152it [00:06, 27.16it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 155it [00:06, 26.70it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 158it [00:06, 26.28it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 161it [00:06, 26.66it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 164it [00:06, 26.87it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 167it [00:06, 26.11it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 170it [00:06, 26.37it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 173it [00:07, 26.70it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 176it [00:07, 26.56it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 179it [00:07, 26.78it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 182it [00:07, 26.74it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 185it [00:07, 25.52it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 188it [00:07, 23.68it/s]\u001b[A\n",
      "Loss: 0.05560298387092158 Train: 0.9336204999660637 Test: 0.9245614266426178 : 2620it [03:36, 12.09it/s][A\n",
      "Loss: 0.055597126483917236 Train: 0.9541863795146673 Test: 0.9235167656130201 : 3687it [02:29, 27.36it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e1d7e15f74f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "num_batches = int(np.ceil(X_train.shape[0] / batch_size))\n",
    "\n",
    "pbar = tqdm(itertools.count(0))\n",
    "for step in pbar:\n",
    "    i = step % num_batches\n",
    "    # Populate feed_dict; duplicated code for num and cat\n",
    "    s = slice(batch_size * i, batch_size * (i + 1))\n",
    "    feed_dict = {nn_kp: 0.95,\n",
    "                 nn_lr: 0.001 if step < 800 else 0.0001,\n",
    "                 nn_X: X_train[s],\n",
    "                 nn_y: y_train[s, np.newaxis],\n",
    "                }\n",
    "    del i\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        _, l, y = sess.run([nn_train, nn_loss, nn_preds], feed_dict)\n",
    "        d = \"Loss: {} \".format(l)\n",
    "        d += \"Train: {} \".format(r_squared(y_train[s], y.ravel()))\n",
    "        y = sess.run(nn_preds, {nn_kp: 1.0,\n",
    "                                nn_X: X_test,\n",
    "                                nn_y: y_test[:, np.newaxis]})\n",
    "        d += \"Test: {} \".format(r_squared(y_test, y.ravel()))\n",
    "        pbar.set_description(d)\n",
    "    else:\n",
    "        sess.run(nn_train, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.summary.writer.writer.FileWriter at 0x7fe9f279e860>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "Loss: 0.055597126483917236 Train: 0.9541863795146673 Test: 0.9235167656130201 : 3687it [02:48, 21.89it/s]"
     ]
    }
   ],
   "source": [
    "tf.summary.FileWriter(\"faceoff/\", graph=sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for KRR fitting: 0.549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF\n",
    "import time\n",
    "\n",
    "# Fit KernelRidge with parameter selection based on 5-fold cross validation\n",
    "param_grid = {\"alpha\": [1e0, 1e-1, 1e-2, 1e-3],\n",
    "              \"kernel\": [RBF(l)\n",
    "                         for l in np.logspace(-2, 2, 10)]}\n",
    "kr = GridSearchCV(KernelRidge(), cv=5, param_grid=param_grid)\n",
    "stime = time.time()\n",
    "kr.fit(X_train[:100], y_train[:100])\n",
    "print(\"Time for KRR fitting: %.3f\" % (time.time() - stime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 181586.72233875]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 180537.74127184]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 179500.65675795]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 178476.56694212]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 177466.08404523]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 176469.42592986]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 175486.5617425]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 174517.32678109]\n",
      "Caught KeyboardInterrupt, setting model                  with most recent state.\n"
     ]
    }
   ],
   "source": [
    "Z = np.random.rand(1000, X_train.shape[1])\n",
    "rbf = GPflow.kernels.RBF(X_train.shape[1], variance=1, ARD=True)\n",
    "m = GPflow.sgpr.SGPR(X_train, y_train[:,None], kern=rbf, Z=Z)\n",
    "def logger(x):\n",
    "    if (logger.i % 10) == 0:\n",
    "        print(x, m._objective(x)[0])\n",
    "    logger.i+=1\n",
    "logger.i = 0\n",
    "\n",
    "m.optimize(method=tf.train.AdamOptimizer(), callback=logger)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: -4.42959616572\n",
      "Test: -4.39652614283\n"
     ]
    }
   ],
   "source": [
    "y, _ = m.predict_y(X_train)\n",
    "print(\"Train:\", r_squared(y_train, y.flatten()))\n",
    "y, _ = m.predict_y(X_test)\n",
    "print(\"Test:\", r_squared(y_test, y.flatten()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle_utils as pu\n",
    "import imp\n",
    "import GPy\n",
    "import gmm_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Importing BostonHousing\n",
      "+++ Importing Ionosphere\n",
      "V2 ; must have more than 1 possible value\n",
      "+++ Importing Servo\n",
      "+++ Importing Soybean\n",
      "+++ Importing LetterRecognition\n",
      "+++ Importing BreastCancer\n",
      "+++ Importing Shuttle\n"
     ]
    }
   ],
   "source": [
    "dset_complete = datasets.datasets()[\"BostonHousing\"][0].astype(np.float64)\n",
    "dset = pu.load(\"impute_benchmark/amputed_BostonHousing_MCAR_rows_0.1.pkl.gz\")\n",
    "mog = pu.load(\"impute_benchmark/imputed_BGMM_20_BostonHousing_MCAR_rows_0.1/params.pkl.gz\")\n",
    "mog['means'] = mog['means'][:, 1:]\n",
    "mog['covariances'] = mog['covariances'][:, 1:, 1:]\n",
    "\n",
    "test_mask = np.random.rand(len(dset)) < 0.2\n",
    "\n",
    "norm_mean = dset[~test_mask].mean()\n",
    "norm_std = dset[~test_mask].std()\n",
    "\n",
    "dset = (dset - norm_mean) / norm_std\n",
    "dset_nan = dset.copy()\n",
    "dset = dset.fillna(0)\n",
    "dset_var = dset.applymap(lambda x: 1 if np.isnan(x) else 0)\n",
    "\n",
    "y_train = dset.values[~test_mask, 2]\n",
    "X_train = np.concatenate([dset.values[~test_mask, :2], dset.values[~test_mask, 3:]], axis=1)\n",
    "X_train_var = np.concatenate([dset_var.values[~test_mask, :2], dset_var.values[~test_mask, 3:]], axis=1)\n",
    "X_train_nan = np.concatenate([dset_var.values[~test_mask, :2], dset_nan.values[~test_mask, 3:]], axis=1)\n",
    "y_test = dset.values[test_mask, 2]\n",
    "X_test = np.concatenate([dset_var.values[test_mask, :2], dset.values[test_mask, 3:]], axis=1)\n",
    "X_test_var = np.concatenate([dset_var.values[test_mask, :2], dset_var.values[test_mask, 3:]], axis=1)\n",
    "X_test_nan = np.concatenate([dset_var.values[test_mask, :2], dset_nan.values[test_mask, 3:]], axis=1)\n",
    "\n",
    "dset_complete_norm = ((dset_complete - norm_mean)/norm_std)\n",
    "X_train_complete = np.concatenate([dset_complete_norm.values[~test_mask, :2],\n",
    "                                   dset_complete_norm.values[~test_mask, 3:]], axis=1)\n",
    "X_test_complete = np.concatenate([dset_complete_norm.values[test_mask, :2],\n",
    "                                   dset_complete_norm.values[test_mask, 3:]], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertain-Kernel underestimation of similarity.\n",
    "Watch the RBF kernel matrix for these 4 points, and the Uncertain-RBF kernel matrix for the same points below. Even when just doing mean imputation the kernel distance is underestimated less, which results in better performance on the overall imputation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.450075</td>\n",
       "      <td>0.239686</td>\n",
       "      <td>-1.249448</td>\n",
       "      <td>0.32063</td>\n",
       "      <td>-0.119632</td>\n",
       "      <td>0.420212</td>\n",
       "      <td>-0.068943</td>\n",
       "      <td>0.106244</td>\n",
       "      <td>-0.970800</td>\n",
       "      <td>-0.634514</td>\n",
       "      <td>-1.456772</td>\n",
       "      <td>0.440488</td>\n",
       "      <td>-1.043539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.447416</td>\n",
       "      <td>-0.515593</td>\n",
       "      <td>-0.557479</td>\n",
       "      <td>0.32063</td>\n",
       "      <td>-0.696058</td>\n",
       "      <td>0.203324</td>\n",
       "      <td>0.410025</td>\n",
       "      <td>0.517378</td>\n",
       "      <td>-0.853727</td>\n",
       "      <td>-0.964166</td>\n",
       "      <td>-0.290468</td>\n",
       "      <td>0.440488</td>\n",
       "      <td>-0.472334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.447418</td>\n",
       "      <td>-0.515593</td>\n",
       "      <td>-0.557479</td>\n",
       "      <td>0.32063</td>\n",
       "      <td>-0.696058</td>\n",
       "      <td>1.279313</td>\n",
       "      <td>-0.212284</td>\n",
       "      <td>0.517378</td>\n",
       "      <td>-0.853727</td>\n",
       "      <td>-0.964166</td>\n",
       "      <td>-0.290468</td>\n",
       "      <td>0.394368</td>\n",
       "      <td>-1.173982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.424115</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>-0.441182</td>\n",
       "      <td>0.32063</td>\n",
       "      <td>-0.236588</td>\n",
       "      <td>-0.909282</td>\n",
       "      <td>1.147706</td>\n",
       "      <td>1.040026</td>\n",
       "      <td>-0.502508</td>\n",
       "      <td>-0.542944</td>\n",
       "      <td>-1.503424</td>\n",
       "      <td>0.324110</td>\n",
       "      <td>2.382314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim        zn     indus     chas       nox        rm       age  \\\n",
       "1 -0.450075  0.239686 -1.249448  0.32063 -0.119632  0.420212 -0.068943   \n",
       "2 -0.447416 -0.515593 -0.557479  0.32063 -0.696058  0.203324  0.410025   \n",
       "3 -0.447418 -0.515593 -0.557479  0.32063 -0.696058  1.279313 -0.212284   \n",
       "9 -0.424115  0.008906 -0.441182  0.32063 -0.236588 -0.909282  1.147706   \n",
       "\n",
       "        dis       rad       tax   ptratio         b     lstat  \n",
       "1  0.106244 -0.970800 -0.634514 -1.456772  0.440488 -1.043539  \n",
       "2  0.517378 -0.853727 -0.964166 -0.290468  0.440488 -0.472334  \n",
       "3  0.517378 -0.853727 -0.964166 -0.290468  0.394368 -1.173982  \n",
       "9  1.040026 -0.502508 -0.542944 -1.503424  0.324110  2.382314  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_complete_v = (dset_complete.iloc[[0,1,2,8]] - norm_mean) / norm_std\n",
    "dset_complete_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.     0.162  0.149  0.   ]\n",
      " [ 0.162  1.     0.361  0.002]\n",
      " [ 0.149  0.361  1.     0.   ]\n",
      " [ 0.     0.002  0.     1.   ]]\n"
     ]
    }
   ],
   "source": [
    "k = GPy.kern.RBF(dset_complete.shape[1])\n",
    "print(k.K(dset_complete_v.values).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 506)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcmat = ((dset_complete - norm_mean)/norm_std).values\n",
    "\n",
    "diff = dset_nan.values[:, np.newaxis, :] - dcmat[np.newaxis, :, :]\n",
    "missing = np.isnan(diff)\n",
    "diff[missing] = 0\n",
    "dist = np.sum(diff**2, axis=2)\n",
    "correct = missing.shape[2] / np.sum(~missing, axis=2)\n",
    "bad_kernel_dist = np.exp(-.5 * dist * correct)\n",
    "\n",
    "knn = np.argsort(-bad_kernel_dist, axis=1)[:, 1:6]\n",
    "m = dcmat[knn]\n",
    "\n",
    "diff = m[:, np.newaxis, :, np.newaxis, :] - m[np.newaxis, :, np.newaxis, :, :]\n",
    "all_dist = np.sum(diff**2, axis=4)\n",
    "dist = np.mean(all_dist, axis=(2,3))\n",
    "#K = np.mean(all_K, axis=(2,3))\n",
    "K = np.exp(-.5 * dist)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.   ,  0.037,  0.117,  0.09 ],\n",
       "       [ 0.037,  1.   ,  0.046,  0.035],\n",
       "       [ 0.117,  0.046,  1.   ,  0.364],\n",
       "       [ 0.09 ,  0.035,  0.364,  1.   ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.flat[::K.shape[0]+1] = 1\n",
    "K[:4, :4].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.249448</td>\n",
       "      <td>0.320630</td>\n",
       "      <td>-0.119632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.068943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.970800</td>\n",
       "      <td>-0.634514</td>\n",
       "      <td>-1.456772</td>\n",
       "      <td>0.440488</td>\n",
       "      <td>-1.043539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.447416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.557479</td>\n",
       "      <td>-3.110981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.410025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.853727</td>\n",
       "      <td>-0.964166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.472334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.447418</td>\n",
       "      <td>-0.515593</td>\n",
       "      <td>-0.557479</td>\n",
       "      <td>0.320630</td>\n",
       "      <td>-0.696058</td>\n",
       "      <td>1.279313</td>\n",
       "      <td>-0.212284</td>\n",
       "      <td>0.517378</td>\n",
       "      <td>-0.853727</td>\n",
       "      <td>-0.964166</td>\n",
       "      <td>-0.290468</td>\n",
       "      <td>0.394368</td>\n",
       "      <td>-1.173982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.424115</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>-0.441182</td>\n",
       "      <td>0.320630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.040026</td>\n",
       "      <td>-0.502508</td>\n",
       "      <td>-0.542944</td>\n",
       "      <td>-1.503424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.382314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim        zn     indus      chas       nox        rm       age  \\\n",
       "1       NaN       NaN -1.249448  0.320630 -0.119632       NaN -0.068943   \n",
       "2 -0.447416       NaN -0.557479 -3.110981       NaN       NaN  0.410025   \n",
       "3 -0.447418 -0.515593 -0.557479  0.320630 -0.696058  1.279313 -0.212284   \n",
       "9 -0.424115  0.008906 -0.441182  0.320630       NaN       NaN       NaN   \n",
       "\n",
       "        dis       rad       tax   ptratio         b     lstat  \n",
       "1       NaN -0.970800 -0.634514 -1.456772  0.440488 -1.043539  \n",
       "2       NaN -0.853727 -0.964166       NaN       NaN -0.472334  \n",
       "3  0.517378 -0.853727 -0.964166 -0.290468  0.394368 -1.173982  \n",
       "9  1.040026 -0.502508 -0.542944 -1.503424       NaN  2.382314  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_nan_v = dset_nan.iloc[[0,1,2,8], :]\n",
    "dset_nan_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#full_mog = pu.load(\"impute_benchmark/imputed_BGMM_20_BostonHousing_MCAR_rows_0.1/params.pkl.gz\")\n",
    "#uk = mog_rbf.UncertainMoGRBFWhite(dset_nan_v.shape[1], full_mog)\n",
    "#print(uk.K(dset_nan_v.values).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.     0.     0.095  0.001]\n",
      " [ 0.     1.     0.     0.   ]\n",
      " [ 0.095  0.     1.     0.   ]\n",
      " [ 0.001  0.     0.     1.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(k.K(dset_nan_v.fillna(0).values).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large variance in density estimation\n",
    "Below are shown the square root of the covariance matrices of the density distribution for points \"1\" and \"2\". Notice the large standard deviations in the diagonal!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d = gmm_impute.conditional_mog(full_mog, dset_nan_v.values[0], np.isnan(dset_nan_v.values[0]))\n",
    "np.sqrt(d['covariances'][1]).round(2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d2 = gmm_impute.conditional_mog(full_mog, dset_nan_v.values[1], np.isnan(dset_nan_v.values[1]))\n",
    "np.sqrt(d2['covariances'][1]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remedy: k-Nearest Neighbours\n",
    "\n",
    "We can fill the values of a point with the values of the $k$ neighbours closest to it, and calculate the estimated expected kernel from that."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%R -o dist.M -i dset_nan_v -i dset_complete_v\n",
    "dist.M <- dist(dset_complete_v)\n",
    "dist.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.   ,  0.162,  0.149,  0.   ],\n",
       "        [ 0.162,  1.   ,  0.361,  0.002],\n",
       "        [ 0.149,  0.361,  1.   ,  0.   ],\n",
       "        [ 0.   ,  0.002,  0.   ,  1.   ]]),\n",
       " array([[ 1.   ,  0.   ,  0.185,  0.   ],\n",
       "        [ 0.   ,  1.   ,  0.   ,  0.   ],\n",
       "        [ 0.185,  0.   ,  1.   ,  0.   ],\n",
       "        [ 0.   ,  0.   ,  0.   ,  1.   ]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adapted_dist(a, b):\n",
    "    diff = a-b\n",
    "    mask = ~np.isnan(diff)\n",
    "    return np.dot(diff[mask], diff[mask]) * len(mask) / np.sum(mask)\n",
    "\n",
    "def dist_matrix(df):\n",
    "    out = np.zeros([len(df)]*2)\n",
    "    for i in range(len(df)-1):\n",
    "        for j in range(i+1, len(df)):\n",
    "            out[j, i] = adapted_dist(df.values[j], df.values[i])\n",
    "    return out + out.T\n",
    "#d = 1.949611\n",
    "M = dist_matrix(dset_nan_v)\n",
    "#adapted_dist(*dset_nan_v.values[[0, 2]])\n",
    "k.K(dset_complete_v.values).round(3), np.exp(-.5*M).round(3),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CorrectedRBF(GPy.kern.src.kern.Kern):\n",
    "    def __init__(self, input_dim, white_var=1., rbf_var=1., lengthscale=None, ARD=False, active_dims=None, name='corrected_rbf'):\n",
    "        super(CorrectedRBF, self).__init__(input_dim, active_dims, name)\n",
    "        #self.white_var = GPy.core.parameterization.Param('white_var', white_var)\n",
    "        self.rbf_var = GPy.core.parameterization.Param('rbf_var', rbf_var)\n",
    "        if lengthscale is None:\n",
    "            if ARD:\n",
    "                lengthscale = np.ones([input_dim], dtype=np.float64)\n",
    "            else:\n",
    "                lengthscale = np.ones([], dtype=np.float64)\n",
    "        self.lengthscale = GPy.core.parameterization.Param('lengthscale', lengthscale)\n",
    "        #self.link_parameters(self.white_var, self.rbf_var, self.lengthscale)\n",
    "        self.link_parameters(self.rbf_var, self.lengthscale)\n",
    "\n",
    "        \n",
    "    def K(self, X, X2=None):\n",
    "        if X2 is None:\n",
    "            V = X\n",
    "        else:\n",
    "            V = X2\n",
    "        diff = X[:, np.newaxis, :] - V[np.newaxis, :, :]\n",
    "        missing = np.isnan(diff)\n",
    "        diff[missing] = 0\n",
    "        correct = missing.shape[2] / np.sum(~missing, axis=2)\n",
    "        out = self.rbf_var * np.exp(-.5 * np.sum(diff**2/self.lengthscale, axis=2) * correct)\n",
    "        if X2 is None:\n",
    "            out.flat[::out.shape[0]] += self.white_var\n",
    "        return out\n",
    "\n",
    "    def Kdiag(self, X):\n",
    "        return (self.rbf_var)*np.ones([len(X)], dtype=np.float64)\n",
    "    \n",
    "    def update_gradients_full(self, dL_dK, X, X2):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from paramz.caching import Cache_this\n",
    "\n",
    "class KNNRBF(CorrectedRBF):\n",
    "    def __init__(self, input_dim, complete_dset, n_neighbours=5, white_var=1., rbf_var=1., lengthscale=None, ARD=False, active_dims=None, name='corrected_rbf'):\n",
    "        super(KNNRBF, self).__init__(input_dim, white_var, rbf_var, lengthscale, ARD, active_dims, name)\n",
    "        self.n_neighbours = n_neighbours\n",
    "        self.complete_dset = complete_dset\n",
    "\n",
    "    #@Cache_this(limit=3, ignore_args=())\n",
    "    def neighbours(self, X):\n",
    "        diff = X[:, np.newaxis, :] - self.complete_dset[np.newaxis, :, :]\n",
    "        missing = np.isnan(diff)\n",
    "        diff[missing] = 0\n",
    "        dist = np.sum((diff/self.lengthscale)**2, axis=2)\n",
    "        correct = missing.shape[2] / np.sum(~missing, axis=2)\n",
    "        bad_kernel_dist = np.exp(-.5 * dist * correct)\n",
    "        neighbours_i = np.argsort(bad_kernel_dist, axis=-1)[..., -1:] #-self.n_neighbours:-1]\n",
    "        return self.complete_dset[neighbours_i]\n",
    "\n",
    "    #@Cache_this(limit=3, ignore_args=())\n",
    "    def _K_components(self, X, X2):\n",
    "        #X_samples = self.neighbours(X).copy()\n",
    "        #observed = ~np.isnan(X)\n",
    "        #np.transpose(X_samples, (1, 0, 2))[:, observed] = X[observed]\n",
    "        X_samples = X[:, np.newaxis, :]\n",
    "        if X2 is None:\n",
    "            V_samples = X_samples\n",
    "        else:\n",
    "            #V_samples = self.neighbours(X2).copy()\n",
    "            #V_observed = ~np.isnan(X2)\n",
    "            #np.transpose(V_samples, (1, 0, 2))[:, V_observed] = X2[V_observed]\n",
    "            V_samples = X2[:, np.newaxis, :]\n",
    "\n",
    "        diff = X_samples[:, np.newaxis, :, np.newaxis, :] - V_samples[np.newaxis, :, np.newaxis, :, :]\n",
    "        diff_sq = (diff/self.lengthscale)**2\n",
    "        all_rad = np.sum(diff_sq, axis=4)\n",
    "        kernel = np.exp(-.5 * all_rad)\n",
    "        return kernel, diff, diff_sq, all_rad\n",
    "    \n",
    "    #@Cache_this(limit=3, ignore_args=())\n",
    "    def K(self, X, X2=None):\n",
    "        kernel, _, _, _ = self._K_components(X, X2)\n",
    "        out = self.rbf_var * np.mean(kernel, axis=(2,3))\n",
    "        #if X2 is None:\n",
    "        #    out.flat[::out.shape[0]+1] = self.rbf_var  # + self.white_var\n",
    "        return out\n",
    "    \n",
    "    #@Cache_this(limit=3, ignore_args=())\n",
    "    def update_gradients_full(self, dL_dK, X, X2):\n",
    "        #if X2 is None:\n",
    "        #    self.white_var.gradient = np.trace(dL_dK)\n",
    "        #else:\n",
    "        #    self.white_var.gradient = 0.0\n",
    "\n",
    "        kernel, diff, diff_sq, all_rad = self._K_components(X, X2)\n",
    "        prob_norm = kernel.shape[2] * kernel.shape[3]\n",
    "        self.rbf_var.gradient = np.sum(dL_dK * np.mean(kernel, axis=(2,3)))\n",
    "        \n",
    "        if self.lengthscale.shape[0] == 1:\n",
    "            grad_l = dL_dK * np.mean(all_rad * kernel, axis=(2,3)) / self.lengthscale\n",
    "        else:\n",
    "            grad_l = dL_dK[:, :, np.newaxis] * np.mean(\n",
    "                diff**2 * kernel[:, :, :, :, np.newaxis], axis=(2,3)) / self.lengthscale**3\n",
    "        grad_l = np.sum(grad_l, axis=(0, 1)) * self.rbf_var\n",
    "        self.lengthscale.gradient = grad_l\n",
    "        print(\"update_Gradients_full\")\n",
    "        print(self.lengthscale.gradient, self.rbf_var.gradient)\n",
    "        print(np.array(self.lengthscale), np.array(self.rbf_var))\n",
    "        \n",
    "    #@Cache_this(limit=3, ignore_args=())\n",
    "    def update_gradients_diag(self, dL_dKdiag, X):\n",
    "        \"\"\"\n",
    "        Given the derivative of the objective with respect to the diagonal of\n",
    "        the covariance matrix, compute the derivative wrt the parameters of\n",
    "        this kernel and stor in the <parameter>.gradient field.\n",
    "        See also update_gradients_full\n",
    "        \"\"\"\n",
    "        g = np.sum(dL_dKdiag)\n",
    "        self.rbf_var.gradient = g\n",
    "        self.white_var.gradient = g\n",
    "        self.lengthscale.gradient = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import knn_kernel\n",
    "imp.reload(knn_kernel)\n",
    "from knn_kernel import RBFWhiteKNNCheating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_lengthscale = np.array(m.kern.lengthscale)\n",
    "#_white_var = np.array(m.kern.white_var)\n",
    "#_rbf_var = np.array(m.kern.rbf_var)\n",
    "_lengthscale = 1.3829171\n",
    "_rbf_var =  0.85418\n",
    "_white_var = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95418     0.37180111  0.35598372  0.20776747]\n",
      " [ 0.37180111  0.95418     0.49114023  0.43354751]\n",
      " [ 0.35598372  0.49114023  0.95418     0.73788622]\n",
      " [ 0.20776747  0.43354751  0.73788622  0.95418   ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 380.71782]), array([ 5680.69451979]), array([ 4747.04128843]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbfk = GPy.kern.RBF(X_train.shape[1], variance=_rbf_var,\n",
    "                    lengthscale=_lengthscale, ARD=False) + GPy.kern.White(X_train.shape[1], variance=_white_var)\n",
    "print(rbfk.K(X_train_complete[:4]))\n",
    "\n",
    "rbfk.update_gradients_full(rbfk.K(X_train_complete), X_train_complete, None)\n",
    "rbfk.white.variance.gradient, rbfk.rbf.variance.gradient, rbfk.rbf.lengthscale.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95418     0.37180111  0.35598372  0.20776747]\n",
      " [ 0.37180111  0.95418     0.49114023  0.43354751]\n",
      " [ 0.35598372  0.49114023  0.95418     0.73788622]\n",
      " [ 0.20776747  0.43354751  0.73788622  0.95418   ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 380.71782]), array([ 5680.69451979]), array([ 4747.04128843]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pknn = RBFWhiteKNN(X_train_complete, rbf_var=_rbf_var, white_var=_white_var,\n",
    "                    lengthscale=_lengthscale, ARD=False)\n",
    "print(pknn.K(X_train_complete[:4]))\n",
    "pknn.update_gradients_full(pknn.K(X_train_complete), X_train_complete, None)\n",
    "pknn.white.variance.gradient, pknn.rbf.variance.gradient, pknn.rbf.lengthscale.gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here starts the actual regressor faceoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r_squared(y_true, y):\n",
    "    u = np.sum((y-y_true)**2)\n",
    "    v = np.sum((y_true - np.mean(y_true))**2)\n",
    "    return 1 - u/v\n",
    "def rmse(y_true, y):\n",
    "    return np.mean((y_true - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False, True, True, False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(y_train)), np.all(np.isfinite(X_train)), np.all(np.isfinite(X_train_nan)), np.all(np.isfinite(y_test)), np.all(np.isfinite(X_test)), np.all(np.isfinite(X_test_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.0044938320452\n",
      "Test: 0.265921953233\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1,\n",
    "                           max_features=int(np.floor(X_train.shape[1])/3),\n",
    "                           bootstrap=False,\n",
    "                           min_samples_split=5)\n",
    "rf.fit(X_train, y_train)\n",
    "#train_perf = rf.score(X_train, y_train)\n",
    "#test_perf = rf.score(X_test, y_test)\n",
    "#print(\"Test: {:.4f}, Training: {:.4f}\".format(test_perf, train_perf))\n",
    "y_train_pred = rf.predict(X_train)\n",
    "print(\"Train:\", rmse(y_train, y_train_pred))\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print(\"Test:\", rmse(y_test, y_test_pred))\n",
    "\n",
    "for i in range(0):\n",
    "    rf.fit(X_train, y_train - y_train_pred)\n",
    "    y_train_pred += rf.predict(X_train)\n",
    "    print(\"Train {:d}:\".format(i), rmse(y_train, y_train_pred))\n",
    "    y_test_pred += rf.predict(X_test)\n",
    "    print(\"Test {:d}:\".format(i), rmse(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: \t\t\t\t L-BFGS-B (Scipy implementation)\n",
      "f(x_opt): \t\t\t\t 249.626\n",
      "Number of function evaluations: \t 111\n",
      "Optimization status: \t\t\t Converged\n",
      "Time elapsed: \t\t\t\t 0:01:41.975566\n",
      "\n",
      "Training time: 103.68197178840637 seconds\n",
      "Train: 0.0450459458188\n",
      "Test: 0.177922877924\n",
      "Test time: 0.3075854778289795 seconds\n",
      "neighbours time: 4.78781533241272 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  knn.           </b></th><th><b>          value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  rbf.variance   </td><td class=tg-right>  1.25069728062</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale</td><td class=tg-right>          (12,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  white.variance </td><td class=tg-right>0.0408907338565</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<knn_kernel.RBFWhiteKNNCheating at 0x7efc887904a8>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import GPy\n",
    "import time\n",
    "start = time.time()\n",
    "m = GPy.models.GPRegression(X_train_nan, y_train[:,np.newaxis],\n",
    "                            kernel=RBFWhiteKNNCheating(X_train_complete, ARD=True)\n",
    "                           )\n",
    "print(m.optimize(optimizer='bfgs'))\n",
    "print(\"Training time:\", time.time() -start, \"seconds\")\n",
    "start = time.time()\n",
    "\n",
    "y_train_pred = m.predict(X_train_nan)[0].flatten()\n",
    "print(\"Train:\", rmse(y_train, y_train_pred))\n",
    "y_test_pred = m.predict(X_test_nan)[0].flatten()\n",
    "print(\"Test:\", rmse(y_test, y_test_pred))\n",
    "print(\"Test time:\", time.time() -start, \"seconds\")\n",
    "\n",
    "m.kern.print_times()\n",
    "\n",
    "m.kern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "/home/adria/venv/bin/python3: undefined symbol: openblas_set_num_threads",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-1603eeff07a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopenblas_num_threads\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopenblas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopenblas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     m = GPy.models.GPRegression(X_train_nan, y_train[:,np.newaxis],\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MIMIC/ts-baselines/timeless-imputation/openblas_num_threads.py\u001b[0m in \u001b[0;36mnum_threads\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \"\"\"\n\u001b[1;32m     63\u001b[0m     \u001b[0mold_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_num_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mset_num_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MIMIC/ts-baselines/timeless-imputation/openblas_num_threads.py\u001b[0m in \u001b[0;36mset_num_threads\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset_num_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m\"\"\"Set the current number of threads used by the OpenBLAS server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mopenblas_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenblas_set_num_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/ctypes/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/ctypes/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name_or_ordinal)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_ordinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FuncPtr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_ordinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_ordinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_or_ordinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: /home/adria/venv/bin/python3: undefined symbol: openblas_set_num_threads"
     ]
    }
   ],
   "source": [
    "import GPy\n",
    "import time\n",
    "import openblas_num_threads as openblas\n",
    "\n",
    "with openblas.num_threads(2):\n",
    "    start = time.time()\n",
    "    m = GPy.models.GPRegression(X_train_nan, y_train[:,np.newaxis],\n",
    "                                kernel=RBFWhiteKNNCheating(X_train_complete, ARD=True, n_neighbours=3)\n",
    "                               )\n",
    "    print(m.optimize(optimizer='bfgs'))\n",
    "    print(\"Training time:\", time.time() -start, \"seconds\")\n",
    "    start = time.time()\n",
    "\n",
    "    y_train_pred = m.predict(X_train_nan)[0].flatten()\n",
    "    print(\"Train:\", rmse(y_train, y_train_pred))\n",
    "    y_test_pred = m.predict(X_test_nan)[0].flatten()\n",
    "    print(\"Test:\", rmse(y_test, y_test_pred))\n",
    "    print(\"Test time:\", time.time() -start, \"seconds\")\n",
    "\n",
    "    m.kern.print_times()\n",
    "\n",
    "m.kern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: \t\t\t\t L-BFGS-B (Scipy implementation)\n",
      "f(x_opt): \t\t\t\t 219.657\n",
      "Number of function evaluations: \t 113\n",
      "Optimization status: \t\t\t Converged\n",
      "Time elapsed: \t\t\t\t 0:00:03.751702\n",
      "\n",
      "Train: 0.0916575548475\n",
      "Test: 0.15630385646\n"
     ]
    }
   ],
   "source": [
    "import GPy\n",
    "m2 = GPy.models.GPRegression(X_train_complete, y_train[:,np.newaxis],\n",
    "                            kernel=GPy.kern.RBF(X_train.shape[1], ARD=True) + GPy.kern.White(X_train.shape[1])\n",
    "                           )\n",
    "print(m2.optimize(optimizer='bfgs'))\n",
    "y_train_pred = m2.predict(X_train_complete)[0].flatten()\n",
    "print(\"Train:\", rmse(y_train, y_train_pred))\n",
    "y_test_pred = m2.predict(X_test_complete)[0].flatten()\n",
    "print(\"Test:\", rmse(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  knn.               </b></th><th><b>         value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  sum.rbf.variance   </td><td class=tg-right>0.734089641845</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  sum.rbf.lengthscale</td><td class=tg-right>         (12,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  sum.white.variance </td><td class=tg-right>           1.0</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<__main__.ParasiteKNN at 0x7efc8891a6d8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.kern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: \t\t\t\t L-BFGS-B (Scipy implementation)\n",
      "f(x_opt): \t\t\t\t 235.030\n",
      "Number of function evaluations: \t 146\n",
      "Optimization status: \t\t\t Converged\n",
      "Time elapsed: \t\t\t\t 0:00:05.112302\n",
      "\n",
      "Train: 0.0984362175666\n",
      "Test: 0.136451488985\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  sum.           </b></th><th><b>          value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  rbf.variance   </td><td class=tg-right> 0.945813971104</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale</td><td class=tg-right>          (12,)</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  white.variance </td><td class=tg-right>0.0592193822493</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.kern.src.add.Add at 0x7efc88905f28>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import GPy\n",
    "m2 = GPy.models.GPRegression(X_train_complete, y_train[:,np.newaxis],\n",
    "                            kernel=GPy.kern.RBF(X_train.shape[1], ARD=True) + GPy.kern.White(X_train.shape[1])\n",
    "                           )\n",
    "print(m2.optimize(optimizer='bfgs'))\n",
    "y_train_pred = m2.predict(X_train_complete)[0].flatten()\n",
    "print(\"Train:\", rmse(y_train, y_train_pred))\n",
    "y_test_pred = m2.predict(X_test_complete)[0].flatten()\n",
    "print(\"Test:\", rmse(y_test, y_test_pred))\n",
    "m2.kern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".tg  {padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\">\n",
       "\n",
       "<tr>\n",
       "  <th><b>index</b></th>\n",
       "  <th><b>GP_regression.rbf.lengthscale</b></th>\n",
       "  <th><b>constraints</b></th><th><b>priors</b></th>\n",
       "</tr>\n",
       "<tr><td class=tg-left>  [0]  </td><td class=tg-right>                  10.32058803</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [1]  </td><td class=tg-right>                   0.58965222</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [2]  </td><td class=tg-right>                   1.00000000</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [3]  </td><td class=tg-right>                   0.50366224</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [4]  </td><td class=tg-right>                  98.05990293</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [5]  </td><td class=tg-right>                   8.66720458</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [6]  </td><td class=tg-right>                 141.49786358</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [7]  </td><td class=tg-right>                   0.34257290</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [8]  </td><td class=tg-right>                   0.87194708</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [9]  </td><td class=tg-right>                   3.91857484</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [10] </td><td class=tg-right>                  56.31513904</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>\n",
       "<tr><td class=tg-left>  [11] </td><td class=tg-right>                   5.20989461</td><td class=tg-left>    +ve    </td><td class=tg-left>      </td></tr>"
      ],
      "text/plain": [
       "\u001b[1mGP_regression.rbf.lengthscale\u001b[0;0m:\n",
       "Param([  10.32058803,    0.58965222,    1.        ,    0.50366224,\n",
       "         98.05990293,    8.66720458,  141.49786358,    0.3425729 ,\n",
       "          0.87194708,    3.91857484,   56.31513904,    5.20989461])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.kern.lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimal_lengthscale = np.array(m.kern.lengthscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82875605,  0.526138  ,  0.5119024 , ...,  0.28232418,\n",
       "         0.24598097,  0.225607  ],\n",
       "       [ 0.526138  ,  0.82875605,  0.62199017, ...,  0.43940945,\n",
       "         0.43584892,  0.42275461],\n",
       "       [ 0.5119024 ,  0.62199017,  0.82875605, ...,  0.24261259,\n",
       "         0.37036444,  0.28296319],\n",
       "       ..., \n",
       "       [ 0.28232418,  0.43940945,  0.24261259, ...,  0.82875605,\n",
       "         0.57008071,  0.62453154],\n",
       "       [ 0.24598097,  0.43584892,  0.37036444, ...,  0.57008071,\n",
       "         0.82875605,  0.76806324],\n",
       "       [ 0.225607  ,  0.42275461,  0.28296319, ...,  0.62453154,\n",
       "         0.76806324,  0.82875605]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ground-truth RBF kernel\n",
    "m.kern.K(X_train_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt caught, calling on_optimization_end() to round things up\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-335-0a013eb6d6c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   \u001b[0mX_variance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_var\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                             )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/core/sparse_gp_mpi.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, optimizer, start, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_IN_OPTIMIZATION_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpi_comm\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSparseGP_MPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpi_comm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSparseGP_MPI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/core/gp.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, optimizer, start, messages, max_iters, ipython_notebook, clear_after_finish, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_optimization_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipython_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_after_finish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KeyboardInterrupt caught, calling on_optimization_end() to round things up\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/model.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, optimizer, start, messages, max_iters, ipython_notebook, clear_after_finish, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mVerboseOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipython_notebook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mipython_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_after_finish\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_after_finish\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_fp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization_runs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/optimization/optimization.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, x_init, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/optimization/optimization.py\u001b[0m in \u001b[0;36mopt\u001b[0;34m(self, x_init, f_fp, f, fp)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mopt_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'factr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfgs_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mopt_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopt_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_fp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 193\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    194\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    195\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/model.py\u001b[0m in \u001b[0;36m_objective_grads\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_objective_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mobj_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_function_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fail_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/parameterized.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, val)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;31m#===========================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/core/sparse_gp_mpi.py\u001b[0m in \u001b[0;36moptimizer_array\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpi_comm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpi_comm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mSparseGP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/core/parameter_core.py\u001b[0m in \u001b[0;36moptimizer_array\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_copy_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_trigger_params_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrigger_parent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/core/updateable.py\u001b[0m in \u001b[0;36mtrigger_update\u001b[0;34m(self, trigger_parent)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m#print \"Warning: updates are off, updating the model will do nothing\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trigger_params_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigger_parent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/core/parameter_core.py\u001b[0m in \u001b[0;36m_trigger_params_changed\u001b[0;34m(self, trigger_parent)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[1;32m    127\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trigger_params_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrigger_parent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fixed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrigger_parent\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_size_transformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/core/observable.py\u001b[0m in \u001b[0;36mnotify_observers\u001b[0;34m(self, which, min_priority)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mwhich\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin_priority\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mcallble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallble\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallble\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/core/observable.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mwhich\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin_priority\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mcallble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallble\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallble\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/core/parameter_core.py\u001b[0m in \u001b[0;36m_parameters_changed_notification\u001b[0;34m(self, me, which)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \"\"\"\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_copy_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m# tells the optimizer array to update on next request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pass_through_notify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_observers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/models/sparse_gp_regression.py\u001b[0m in \u001b[0;36mparameters_changed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mupdate_gradients_sparsegp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpi_comm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpi_comm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSparseGPRegression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/core/sparse_gp_mpi.py\u001b[0m in \u001b[0;36mparameters_changed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mupdate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpi_comm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpi_comm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSparseGP_MPI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/core/sparse_gp.py\u001b[0m in \u001b[0;36mparameters_changed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_marginal_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/core/sparse_gp.py\u001b[0m in \u001b[0;36m_update_gradients\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m                                                     \u001b[0mdL_dpsi0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dL_dpsi0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                                                     \u001b[0mdL_dpsi1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dL_dpsi1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                                                     dL_dpsi2=self.grad_dict['dL_dpsi2'])\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mkerngrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/kern/src/kernel_slice_operations.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(self, dL_dpsi0, dL_dpsi1, dL_dpsi2, Z, variational_posterior)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariational_posterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_Slice_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariational_posterior\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/kern/src/add.py\u001b[0m in \u001b[0;36mupdate_gradients_expectations\u001b[0;34m(self, dL_dpsi0, dL_dpsi1, dL_dpsi2, Z, variational_posterior)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exact_psicomp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mKern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_gradients_expectations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariational_posterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstatic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWhite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/kern/src/kernel_slice_operations.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(self, dL_dpsi0, dL_dpsi1, dL_dpsi2, Z, variational_posterior)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariational_posterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_Slice_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariational_posterior\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/kern/src/kern.py\u001b[0m in \u001b[0;36mupdate_gradients_expectations\u001b[0;34m(self, dL_dpsi0, dL_dpsi1, dL_dpsi2, Z, variational_posterior)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0mhere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \"\"\"\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mdtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsicomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsiDerivativecomputations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariational_posterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-127>\u001b[0m in \u001b[0;36mpsiDerivativecomputations\u001b[0;34m(self, kern, dL_dpsi0, dL_dpsi1, dL_dpsi2, Z, qX)\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/caching.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(obj, *args, **kw)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0mcacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcacher_enabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaching_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/caching.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# If we need to compute, we compute the operation, but fail gracefully, if the operation has an error:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0mnew_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/kern/src/psi_comp/gaussherm.py\u001b[0m in \u001b[0;36mpsiDerivativecomputations\u001b[0;34m(self, kern, dL_dpsi0, dL_dpsi1, dL_dpsi2, Z, qX)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mdL_dkfu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdL_dpsi1\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKfu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdL_dpsi2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_gradients_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdL_dkfu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mdtheta\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mdX_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdZ_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients_X_X2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdL_dkfu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/kern/src/kernel_slice_operations.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(self, dL_dK, X, X2)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_Slice_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdL_dK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/GPy/kern/src/kernel_slice_operations.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *a)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sliced_X\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle_return_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/paramz/parameterized.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, val)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;31m# override the default behaviour, if setting a param, so broadcasting can by used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"parameters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import GPy\n",
    "m = GPy.models.SparseGPRegression(X_train, y_train[:,np.newaxis],\n",
    "                            kernel=GPy.kern.Matern32(X_train.shape[1], ARD=False) + GPy.kern.White(X_train.shape[1]),\n",
    "                                  num_inducing=20,\n",
    "                                  X_variance=X_train_var + 1e-6\n",
    "                            )\n",
    "m.optimize()\n",
    "y, _ = m.predict(X_train)\n",
    "print(\"Train:\", rmse(y_train, y.flatten()))\n",
    "y, _ = m.predict(X_test)\n",
    "print(\"Test:\", rmse(y_test, y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-0.42006788,  1.01905536,  0.68299323, -0.40612554,  0.63205938,\n",
       "          -0.5832783 ,  0.39105928,  0.67011543,  0.35313276, -0.21148562,\n",
       "           0.3739001 ,  1.10710231]]]),\n",
       " array([[ 0.63855337,  0.32716695,  0.        ,  1.04207718, -0.0528659 ,\n",
       "          1.04048448,  0.61910684,  0.2997959 ,  0.54710433,  1.24750701,\n",
       "          0.30055021,  0.        ]]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(gmm_impute)\n",
    "gmm_impute._gmm_impute(mog, X_train_nan[9:10], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  sum.           </b></th><th><b>           value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  rbf.variance   </td><td class=tg-right>   0.86458246011</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale</td><td class=tg-right>   1.41275603781</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  white.variance </td><td class=tg-right>0.00589876098757</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.kern.src.add.Add at 0x7fc837fdec88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.kern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-0.42006788],\n",
       "         [ 1.01905536],\n",
       "         [-0.40612554],\n",
       "         [ 0.63205938],\n",
       "         [-0.5832783 ],\n",
       "         [ 0.39105928],\n",
       "         [ 0.67011543],\n",
       "         [ 0.35313276],\n",
       "         [-0.21148562],\n",
       "         [ 0.3739001 ]]]),\n",
       " array([[[ 0.63855337,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.32716695,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  1.04207718,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , -0.0528659 ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  1.04048448,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.61910684,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.2997959 ,  0.        ,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.54710433,  0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  1.24750701,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,  0.30055021]]]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(mog_rbf)\n",
    "d = mog_rbf.uncertain_point(X_train_nan[9], mog, 1., np.eye(12), single_gaussian_moment_matching=True)\n",
    "d['means'], d['covariances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To compute map took me: 0.4738774299621582\n",
      "FOR REAL [[[-0.15875905]\n",
      "  [ 0.17830032]\n",
      "  [-0.41094708]\n",
      "  [-0.40360746]]]\n"
     ]
    }
   ],
   "source": [
    "imp.reload(mog_rbf)\n",
    "imp.reload(gmm_impute)\n",
    "uk2 = mog_rbf.UncertainMoGRBFWhite(X_train.shape[1], mog, cutoff=1.0, single_gaussian=True)\n",
    "K_uk2 = uk2.K(X_train_nan, X_train_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: you passed a MoG to a GaussianRBFWhite kernel\n",
      "To compute map (rectangular) took me: 0.9276993274688721\n",
      "To compute matrix took me: 0.2105269432067871\n",
      "(408, 408)\n"
     ]
    }
   ],
   "source": [
    "imp.reload(mog_rbf)\n",
    "imp.reload(gmm_impute)\n",
    "uk3 = mog_rbf.UncertainGaussianRBFWhite(X_train.shape[1], mog)\n",
    "K_uk3 = uk3.K(X_train_nan, X_train_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00090383853741499674"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(K_uk3 - K_uk3.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 401)\n",
      "Train: 0.249568009132\n",
      "Test: 0.384448154724\n"
     ]
    }
   ],
   "source": [
    "import mog_rbf\n",
    "import imp\n",
    "import gmm_impute\n",
    "imp.reload(gmm_impute)\n",
    "imp.reload(mog_rbf)\n",
    "\n",
    "uncertain_kern = mog_rbf.UncertainMoGRBFWhite(X_train.shape[1], mog)\n",
    "uncertain_k = GPy.models.GPRegression(X_train_nan, y_train[:, np.newaxis],\n",
    "                                     kernel=uncertain_kern)\n",
    "y, _ = uncertain_k.predict(X_train_nan)\n",
    "print(\"Train:\", rmse(y_train, y.flatten()))\n",
    "y, _ = uncertain_k.predict(X_test_nan)\n",
    "print(\"Test:\", rmse(y_test, y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: you passed a MoG to a GaussianRBFWhite kernel\n",
      "Train: 0.251347573504\n",
      "Test: 0.515770105012\n"
     ]
    }
   ],
   "source": [
    "import mog_rbf\n",
    "import imp\n",
    "import gmm_impute\n",
    "imp.reload(gmm_impute)\n",
    "imp.reload(mog_rbf)\n",
    "\n",
    "uncertain_kern = mog_rbf.UncertainGaussianRBFWhite(X_train.shape[1], mog,\n",
    "                                                   rbf_var=m.kern.rbf.variance,\n",
    "                                                   white_var=m.kern.white.variance,\n",
    "                                                   lengthscale=m.kern.rbf.lengthscale)\n",
    "uncertain_k = GPy.models.GPRegression(X_train_nan, y_train[:, np.newaxis],\n",
    "                                     kernel=uncertain_kern)\n",
    "y, _ = uncertain_k.predict(X_train_nan)\n",
    "print(\"Train:\", rmse(y_train, y.flatten()))\n",
    "y, _ = uncertain_k.predict(X_test_nan)\n",
    "print(\"Test:\", rmse(y_test, y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/adria/venv/lib/python3.5/site-packages/paramz/transformations.py:109: RuntimeWarning:divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.255991811883\n",
      "Test: 0.362862548471\n"
     ]
    }
   ],
   "source": [
    "X_train_alt = X_train_nan.copy()\n",
    "X_test_alt = X_test_nan.copy()\n",
    "\n",
    "for i, X in enumerate(X_train_alt):\n",
    "    mask = np.isnan(X)\n",
    "    d = gmm_impute.conditional_mog(mog, X, mask)\n",
    "    # Perform moment matching to get mean and variance\n",
    "    # https://stats.stackexchange.com/questions/16608/what-is-the-variance-of-the-weighted-mixture-of-two-gaussians\n",
    "    ms = d['means'] * d['weights'][:, np.newaxis]\n",
    "    mean = np.sum(ms, axis=0)\n",
    "    var_mix = np.sum(d['covariances'] * np.eye(d['covariances'].shape[1]), axis=2).sum(axis=0)\n",
    "    var = var_mix + np.sum(ms * d['means'], axis=0) - mean\n",
    "    X_train_alt[i, mask] = mean\n",
    "    X_train_var[i, mask] = var\n",
    "\n",
    "for i, X in enumerate(X_test_alt):\n",
    "    mask = np.isnan(X)\n",
    "    d = gmm_impute.conditional_mog(mog, X, mask)\n",
    "    X_test_alt[i, mask] = np.sum(d['means'] * d['weights'][:, np.newaxis], axis=0)\n",
    "\n",
    "\n",
    "sparse_m = GPy.models.SparseGPRegression(\n",
    "    X_train_alt, y_train[:, np.newaxis],\n",
    "    kernel=(GPy.kern.RBF(X_train.shape[1], ARD=False)\n",
    "                   + GPy.kern.White(X_train.shape[1])),\n",
    "    Z=X_train_alt,\n",
    "    X_variance=X_train_var)\n",
    "#sparse_m.optimize()\n",
    "y, _ = sparse_m.predict(X_train_alt)\n",
    "print(\"Train:\", rmse(y_train, y.flatten()))\n",
    "y, full_cov = sparse_m.predict(X_test, full_cov=True)\n",
    "print(\"Test:\", rmse(y_test, y.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.78635832e+00,   2.06344958e-04,   1.64838064e-05, ...,\n",
       "          4.35285552e-04,   1.00000000e-15,   8.26572097e-04],\n",
       "       [  2.06344958e-04,   2.94234875e+00,   1.27033141e-03, ...,\n",
       "          4.72627943e-01,   1.00000000e-15,   1.87282191e-02],\n",
       "       [  1.64838064e-05,   1.27033141e-03,   2.78212823e+00, ...,\n",
       "          8.27680241e-04,   2.87765037e-03,   1.40391869e-02],\n",
       "       ..., \n",
       "       [  4.35285552e-04,   4.72627943e-01,   8.27680241e-04, ...,\n",
       "          2.93926028e+00,   1.00000000e-15,   5.84986024e-02],\n",
       "       [  1.00000000e-15,   1.00000000e-15,   2.87765037e-03, ...,\n",
       "          1.00000000e-15,   2.71902756e+00,   1.00000000e-15],\n",
       "       [  8.26572097e-04,   1.87282191e-02,   1.40391869e-02, ...,\n",
       "          5.84986024e-02,   1.00000000e-15,   2.80199682e+00]])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import selu\n",
    "import denoising_ae as dae\n",
    "import imp\n",
    "imp.reload(dae)\n",
    "imp.reload(selu)\n",
    "\n",
    "tf_float = tf.float32\n",
    "tf.reset_default_graph()\n",
    "\n",
    "nn_X = tf.placeholder(tf_float, shape=[None, X_train.shape[1]], name=\"X\")\n",
    "nn_y = tf.placeholder(tf_float, shape=[None, 1], name=\"y\")\n",
    "nn_kp = tf.placeholder(tf_float, shape=[], name=\"keep_prob\")\n",
    "nn_lr = tf.placeholder(tf_float, shape=[], name=\"learning_rate\")\n",
    "\n",
    "\n",
    "nn_preds = dae.FC_net(nn_X, [(1024, selu.nlin)]*8 + [(1, None)], selu.initializer, keep_prob=nn_kp)\n",
    "nn_loss = tf.reduce_mean(tf.squared_difference(nn_preds, nn_y))\n",
    "nn_train = tf.train.GradientDescentOptimizer(nn_lr).minimize(nn_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 1it [00:00,  3.25it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 3it [00:00,  4.23it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 5it [00:00,  5.52it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 8it [00:00,  7.19it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 11it [00:00,  9.28it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 14it [00:00, 11.47it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 17it [00:01, 13.87it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 20it [00:01, 16.15it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 23it [00:01, 18.33it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 26it [00:01, 20.51it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 29it [00:01, 21.84it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 32it [00:01, 23.56it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 35it [00:01, 24.51it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 38it [00:01, 25.17it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 41it [00:01, 25.87it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 44it [00:02, 26.36it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 47it [00:02, 26.60it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 50it [00:02, 26.59it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 53it [00:02, 26.87it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 56it [00:02, 27.14it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 59it [00:02, 27.49it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 62it [00:02, 27.45it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 65it [00:02, 27.38it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 68it [00:02, 27.17it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 71it [00:03, 26.09it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 74it [00:03, 26.05it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 77it [00:03, 26.21it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 80it [00:03, 26.16it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 83it [00:03, 26.11it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 86it [00:03, 25.68it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 89it [00:03, 24.57it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 92it [00:03, 24.73it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 95it [00:03, 25.24it/s]\u001b[A\n",
      "Loss: 2.2472610473632812 Train: -1.3396346953249103 Test: -3.2978709281776 : 98it [00:04, 25.93it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 101it [00:04, 17.16it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 104it [00:04, 18.84it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 107it [00:04, 20.02it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 110it [00:04, 21.44it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 113it [00:04, 22.81it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 116it [00:04, 23.97it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 119it [00:05, 24.93it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 122it [00:05, 25.40it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 125it [00:05, 25.89it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 128it [00:05, 26.16it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 131it [00:05, 26.56it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 134it [00:05, 26.75it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 137it [00:05, 26.85it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 140it [00:05, 26.67it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 143it [00:05, 26.69it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 146it [00:06, 26.40it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 149it [00:06, 27.00it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 152it [00:06, 27.16it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 155it [00:06, 26.70it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 158it [00:06, 26.28it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 161it [00:06, 26.66it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 164it [00:06, 26.87it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 167it [00:06, 26.11it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 170it [00:06, 26.37it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 173it [00:07, 26.70it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 176it [00:07, 26.56it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 179it [00:07, 26.78it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 182it [00:07, 26.74it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 185it [00:07, 25.52it/s]\u001b[A\n",
      "Loss: 0.11750867962837219 Train: 0.8464955622592506 Test: 0.8586899906046013 : 188it [00:07, 23.68it/s]\u001b[A\n",
      "Loss: 0.05560298387092158 Train: 0.9336204999660637 Test: 0.9245614266426178 : 2620it [03:36, 12.09it/s][A\n",
      "Loss: 0.055597126483917236 Train: 0.9541863795146673 Test: 0.9235167656130201 : 3687it [02:29, 27.36it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e1d7e15f74f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "num_batches = int(np.ceil(X_train.shape[0] / batch_size))\n",
    "\n",
    "pbar = tqdm(itertools.count(0))\n",
    "for step in pbar:\n",
    "    i = step % num_batches\n",
    "    # Populate feed_dict; duplicated code for num and cat\n",
    "    s = slice(batch_size * i, batch_size * (i + 1))\n",
    "    feed_dict = {nn_kp: 0.95,\n",
    "                 nn_lr: 0.001 if step < 800 else 0.0001,\n",
    "                 nn_X: X_train[s],\n",
    "                 nn_y: y_train[s, np.newaxis],\n",
    "                }\n",
    "    del i\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        _, l, y = sess.run([nn_train, nn_loss, nn_preds], feed_dict)\n",
    "        d = \"Loss: {} \".format(l)\n",
    "        d += \"Train: {} \".format(r_squared(y_train[s], y.ravel()))\n",
    "        y = sess.run(nn_preds, {nn_kp: 1.0,\n",
    "                                nn_X: X_test,\n",
    "                                nn_y: y_test[:, np.newaxis]})\n",
    "        d += \"Test: {} \".format(r_squared(y_test, y.ravel()))\n",
    "        pbar.set_description(d)\n",
    "    else:\n",
    "        sess.run(nn_train, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.summary.writer.writer.FileWriter at 0x7fe9f279e860>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "Loss: 0.055597126483917236 Train: 0.9541863795146673 Test: 0.9235167656130201 : 3687it [02:48, 21.89it/s]"
     ]
    }
   ],
   "source": [
    "tf.summary.FileWriter(\"faceoff/\", graph=sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for KRR fitting: 0.549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF\n",
    "import time\n",
    "\n",
    "# Fit KernelRidge with parameter selection based on 5-fold cross validation\n",
    "param_grid = {\"alpha\": [1e0, 1e-1, 1e-2, 1e-3],\n",
    "              \"kernel\": [RBF(l)\n",
    "                         for l in np.logspace(-2, 2, 10)]}\n",
    "kr = GridSearchCV(KernelRidge(), cv=5, param_grid=param_grid)\n",
    "stime = time.time()\n",
    "kr.fit(X_train[:100], y_train[:100])\n",
    "print(\"Time for KRR fitting: %.3f\" % (time.time() - stime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 181586.72233875]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 180537.74127184]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 179500.65675795]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 178476.56694212]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 177466.08404523]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 176469.42592986]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 175486.5617425]\n",
      "[ 0.42271147  0.10330646  0.66634543 ...,  0.54132327  0.54132327\n",
      "  0.54132327] [ 174517.32678109]\n",
      "Caught KeyboardInterrupt, setting model                  with most recent state.\n"
     ]
    }
   ],
   "source": [
    "Z = np.random.rand(1000, X_train.shape[1])\n",
    "rbf = GPflow.kernels.RBF(X_train.shape[1], variance=1, ARD=True)\n",
    "m = GPflow.sgpr.SGPR(X_train, y_train[:,None], kern=rbf, Z=Z)\n",
    "def logger(x):\n",
    "    if (logger.i % 10) == 0:\n",
    "        print(x, m._objective(x)[0])\n",
    "    logger.i+=1\n",
    "logger.i = 0\n",
    "\n",
    "m.optimize(method=tf.train.AdamOptimizer(), callback=logger)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: -4.42959616572\n",
      "Test: -4.39652614283\n"
     ]
    }
   ],
   "source": [
    "y, _ = m.predict_y(X_train)\n",
    "print(\"Train:\", r_squared(y_train, y.flatten()))\n",
    "y, _ = m.predict_y(X_test)\n",
    "print(\"Test:\", r_squared(y_test, y.flatten()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
